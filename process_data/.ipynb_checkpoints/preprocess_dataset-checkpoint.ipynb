{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_util import *\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 17] File exists: '/home/ubuntu/cs224u/processed_relationships/relationships_story'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-426319d63540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# create the directory to the corresponding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/ubuntu/cs224u/processed_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minput_subreddit\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minput_subreddit\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_story'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: [Errno 17] File exists: '/home/ubuntu/cs224u/processed_relationships/relationships_story'"
     ]
    }
   ],
   "source": [
    "# read jsonl dataset\n",
    "src = \"/home/ubuntu/cs224u/raw_reddit/tldr-training-data.jsonl\"\n",
    "reader = jsonlines.open(src)\n",
    "\n",
    "# choose a subreddit\n",
    "input_subreddit = \"relationships\"\n",
    "\n",
    "# create the directory to this corresponding dataset\n",
    "dst = \"/home/ubuntu/cs224u/processed_\"+input_subreddit+\"/\"+input_subreddit+'_story'\n",
    "os.mkdir(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a corresponding dataset\n",
    "count = 0\n",
    "dic_list = []\n",
    "for dic in reader:\n",
    "    if(\"subreddit\" in dic.keys() and dic[\"subreddit\"] == input_subreddit and \n",
    "       isEnglish(dic[\"summary\"]) == True and  isEnglish(dic[\"content\"]) == True ):\n",
    "        dic_list.append(dic)\n",
    "\n",
    "sample_list = sample(dic_list,100)\n",
    "for dic in sample_list:\n",
    "    create_story_file(dic, dst)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get corresponding list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "result_list = os.listdir(dst)\n",
    "np.random.shuffle(result_list)\n",
    "size = len(result_list)\n",
    "\n",
    "train_list = result_list[0:int(0.8*size)-1]\n",
    "train_str = \"\\n\".join(x for x in train_list)\n",
    "\n",
    "dev_list = result_list[int(0.8*size):int(0.9*size)-1]\n",
    "dev_str = \"\\n\".join(x for x in dev_list)\n",
    "\n",
    "test_list = result_list[int(0.9*size): int(size)-1]\n",
    "test_str = \"\\n\".join(x for x in test_list)\n",
    "\n",
    "#print (int(0.98*size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create three lists\n",
    "#subreddit_type = \"AskReddit\"\n",
    "create_list(input_subreddit, \"_train\", train_str)\n",
    "create_list(input_subreddit, \"_val\", dev_str)\n",
    "create_list(input_subreddit, \"_test\", test_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a baseline result for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directory to the corresponding baseline result\n",
    "make_dir = '/home/ubuntu/cs224u/processed_' +input_subreddit+'/baseline' \n",
    "os.mkdir(make_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dec_dir = make_dir + '/decoded'\n",
    "os.mkdir(make_dec_dir)\n",
    "\n",
    "make_ref_dir = make_dir + '/reference'\n",
    "os.mkdir(make_ref_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t3_1udtww',\n",
       " '6ejvy9',\n",
       " 't3_3yzftu',\n",
       " 't3_4bcuhi',\n",
       " 'di3h5hh',\n",
       " '64tr5t',\n",
       " 't3_29tth3',\n",
       " 'd62d0ho',\n",
       " 'd5axozy']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the name of the test list\n",
    "test_name_list = [x[:-6] for x in test_list]\n",
    "test_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3_4bcuhi\n",
      "t3_1udtww\n",
      "t3_3yzftu\n",
      "t3_29tth3\n",
      "d62d0ho\n",
      "d5axozy\n",
      "di3h5hh\n",
      "6ejvy9\n",
      "64tr5t\n"
     ]
    }
   ],
   "source": [
    "reader = jsonlines.open(src)\n",
    "# create corresponding baseline summarization\n",
    "for dic in reader:\n",
    "    if(\"subreddit\" in dic.keys() and dic[\"subreddit\"] == input_subreddit and isEnglish(dic[\"content\"]) == True):\n",
    "        if(dic[\"id\"] in test_name_list):\n",
    "            print(dic[\"id\"])\n",
    "            create_baseline_summarization_file(dic, make_dec_dir)\n",
    "            create_reference_file(dic, make_ref_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create an example.story (not relavant to here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dic in reader:\n",
    "    if(\"subreddit\" in dic.keys() and dic[\"subreddit\"] == \"AskReddit\" and isEnglish(dic[\"summary\"]) == True and  isEnglish(dic[\"content\"]) == True ):\n",
    "        print(dic)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cwd = os.getcwd()\n",
    "filename = os.path.join(cwd, \"example.story\")\n",
    "file1 = open(filename,\"w\")\n",
    "file1.writelines(dic[\"content\"]+'\\n')\n",
    "#file1.writelines('@hightlight \\n')\n",
    "#file1.writelines(input_dict['summary'])\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic[\"summary\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
