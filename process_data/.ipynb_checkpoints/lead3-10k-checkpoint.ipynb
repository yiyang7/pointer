{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pyrouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the summarization based on first three sentences of the content\n",
    "# and save them as a story/txt file with the same name(?)\n",
    "\n",
    "# choose a subreddit\n",
    "input_subreddit = \"AskReddit\"\n",
    "\n",
    "# read json dataset\n",
    "path = \"/home/ubuntu/cs224u/raw_reddit/\" + \"tldr-training-data.jsonl\"\n",
    "reader = jsonlines.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"/home/ubuntu/cs224u/pointer/log/combine_all_exp/decode_test_400maxenc_4beam_10mindec_120maxdec_ckpt-17502_cov_init\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directory to the corresponding\n",
    "make_dir = \"/home/ubuntu/cs224u/pointer/log/baseline-comebine_all_lead3\"\n",
    "os.mkdir(make_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dec_dir = make_dir + '/decoded'\n",
    "os.mkdir(make_dec_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create corresponding lead-3 file inside the decoded file\n",
    "def Lead_3_Sentence(content):\n",
    "    return (' '.join(re.split(r'(?<=[.:;])\\s', content)[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/cs224u/pointer/log/baseline-comebine_all_lead3/decoded\n"
     ]
    }
   ],
   "source": [
    "src = \"/home/ubuntu/cs224u/pointer/log/baseline-comebine_all_lead3/content\"\n",
    "dest = \"/home/ubuntu/cs224u/pointer/log/baseline-comebine_all_lead3/decoded\"\n",
    "src_files = os.listdir(src)\n",
    "print(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in src_files:\n",
    "    full_content_name = os.path.join(src, file_name)\n",
    "    full_decoded_name = os.path.join(dest, file_name)\n",
    "    fw = open(full_decoded_name, \"w\")\n",
    "    fr = open(full_content_name, \"r\")\n",
    "    content = fr.readlines()[0]\n",
    "    #print(content)\n",
    "    sentence = Lead_3_Sentence(content)\n",
    "    #print(sentence)\n",
    "    fw.write(sentence)\n",
    "    fw.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lead3_sentence_file(filename, ):\n",
    "    filename = os.path.join(\"/home/ubuntu/cs224u/processesd_10_1k/\"+ subreddit_type+\"/\", subreddit_type + input_type + \"list.txt\")\n",
    "    print(filename)\n",
    "    f = open(filename,\"w\")\n",
    "    f.writelines(input_str)\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each file inside the content folder, create a corresponding \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directory to the corresponding\n",
    "make_dir_baseline_summarization_test = cwd + '/'+input_subreddit+'_baseline_summarization_test'\n",
    "os.mkdir(make_dir_baseline_summarization_test)\n",
    "make_dec_baseline_dir = make_dir_baseline_summarization_test + '/decoded'\n",
    "os.mkdir(make_dec_dir)\n",
    "\n",
    "make_ref_baseline_dir = make_dir_make_dir_baseline_summarization_test + '/reference'\n",
    "os.mkdir(make_ref_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_raw = cwd+'/processed_ask/AskReddit_testlist.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create corresponding baseline summarization\n",
    "for dic in reader:\n",
    "    if(\"subreddit\" in dic.keys() and dic[\"subreddit\"] == input_subreddit and isEnglish(dic[\"content\"]) == True and dic.id in test_list):\n",
    "        create_baseline_summarization_file(dic, make_dec_dir)\n",
    "        create_reference_file(dic, make_ref_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrouge import Rouge155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the rouge score\n",
    "def rouge_eval(ref_dir, dec_dir):\n",
    "  \"\"\"Evaluate the files in ref_dir and dec_dir with pyrouge, returning results_dict\"\"\"\n",
    "  r = pyrouge.Rouge155()\n",
    "  r.model_filename_pattern = '#ID#_reference.txt'\n",
    "  r.system_filename_pattern = '(\\d+)_decoded.txt'\n",
    "  r.model_dir = ref_dir\n",
    "  r.system_dir = dec_dir\n",
    "  logging.getLogger('global').setLevel(logging.WARNING) # silence pyrouge logging\n",
    "  rouge_results = r.convert_and_evaluate()\n",
    "  return r.output_to_dict(rouge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rouge_eval(make_ref_dir, make_dec_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_log(results_dict, dir_to_write):\n",
    "  \"\"\"Log ROUGE results to screen and write to file.\n",
    "\n",
    "  Args:\n",
    "    results_dict: the dictionary returned by pyrouge\n",
    "    dir_to_write: the directory where we will write the results to\"\"\"\n",
    "  log_str = \"\"\n",
    "  for x in [\"1\",\"2\",\"l\"]:\n",
    "    log_str += \"\\nROUGE-%s:\\n\" % x\n",
    "    for y in [\"f_score\", \"recall\", \"precision\"]:\n",
    "      key = \"rouge_%s_%s\" % (x,y)\n",
    "      key_cb = key + \"_cb\"\n",
    "      key_ce = key + \"_ce\"\n",
    "      val = results_dict[key]\n",
    "      val_cb = results_dict[key_cb]\n",
    "      val_ce = results_dict[key_ce]\n",
    "      log_str += \"%s: %.4f with confidence interval (%.4f, %.4f)\\n\" % (key, val, val_cb, val_ce)\n",
    "  tf.logging.info(log_str) # log to screen\n",
    "  results_file = os.path.join(dir_to_write, \"ROUGE_results.txt\")\n",
    "  tf.logging.info(\"Writing final ROUGE results to %s...\", results_file)\n",
    "  with open(results_file, \"w\") as f:\n",
    "    f.write(log_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
