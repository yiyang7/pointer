{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import numpy as np\n",
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "from tensorflow.python import pywrap_tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# file_name = \"/home/cs224u/pointer/log/test_exp2/train/\" + \"model.ckpt-0\"\n",
    "# reader = tf.train.NewCheckpointReader(file_name)\n",
    "# var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "\n",
    "# config = tf.ConfigProto(allow_soft_placement=True)\n",
    "# with tf.Session(config=config) as sess:\n",
    "#     # define the new is_training tensor\n",
    "#     embedding_doc = tf.random_normal([10, 128],dtype=tf.float32, name='embedding_doc')\n",
    "\n",
    "#     # now import the graph using the .meta file of the checkpoint\n",
    "#     saver = tf.train.import_meta_graph(\n",
    "#     file_name+\".meta\", input_map={'seq2seq/embedding/embedding_doc:0':embedding_doc})\n",
    "\n",
    "#     # restore all weights using the model checkpoint \n",
    "#     saver.restore(sess, file_name)\n",
    "\n",
    "#     # save updated graph and variables values\n",
    "#     saver.save(sess, file_name)\n",
    "    \n",
    "# finite = []\n",
    "# all_infnan = []\n",
    "# some_infnan = []\n",
    "\n",
    "# for key in sorted(var_to_shape_map.keys()):\n",
    "#     tensor = reader.get_tensor(key)\n",
    "#     print (\"key: \", key)\n",
    "#     print (tensor.shape)\n",
    "#     if np.all(np.isfinite(tensor)):\n",
    "#         finite.append(key)\n",
    "#     else:\n",
    "#         if not np.any(np.isfinite(tensor)):\n",
    "#             all_infnan.append(key)\n",
    "#         else:\n",
    "#             some_infnan.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvalue(ckpt):\n",
    "    reader = pywrap_tensorflow.NewCheckpointReader(ckpt)\n",
    "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "    value = {}\n",
    "    for key in var_to_shape_map:\n",
    "#         if \"Adagrad\" not in key:\n",
    "            value[key] = reader.get_tensor(key)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "[[-3.8002606e-02  1.8546827e-02  1.3938937e-01 ... -4.9497869e-02\n",
      "   3.3019509e-02  3.5647683e-02]\n",
      " [ 7.9455858e-05 -6.6116852e-05  1.3608603e-04 ... -1.5781938e-05\n",
      "   5.8481251e-05 -9.1547277e-05]\n",
      " [-5.8828846e-02  6.7614645e-02 -4.5764863e-02 ...  3.1541102e-02\n",
      "  -4.7071457e-02  1.8059494e-02]\n",
      " ...\n",
      " [ 1.8714922e-02 -3.4154747e-02 -5.7082116e-03 ...  9.0036495e-03\n",
      "  -5.3237779e-03 -3.6183164e-02]\n",
      " [ 8.1216330e-03 -1.5133495e-02 -8.5550675e-04 ... -3.6253810e-02\n",
      "  -1.3013718e-02 -1.7758729e-02]\n",
      " [ 3.4547005e-02 -3.0030517e-02 -1.4005583e-03 ... -2.2262277e-02\n",
      "   1.9773055e-02 -1.0151998e-02]]\n",
      "238410\n",
      "[-5.88189960e-01  6.36716127e-01 -2.73615479e-01 -4.82237428e-01\n",
      "  5.22897661e-01 -2.45039478e-01 -1.81122139e-01 -1.61133274e-01\n",
      "  1.89639717e-01  8.96476626e-01  2.60003954e-01  5.00603676e-01\n",
      " -5.00681341e-01  1.82510480e-01  2.87051201e-01 -3.16324592e-01\n",
      "  4.16229516e-01  7.59478152e-01  1.40891239e-01  2.31299371e-01\n",
      "  1.78590983e-01 -3.56549561e-01  7.23787919e-02 -6.12765774e-02\n",
      " -2.28684410e-01  2.37101510e-01 -4.47375923e-02 -2.75556237e-01\n",
      "  4.56018001e-01  6.59986377e-01 -5.84785752e-02  3.47939640e-01\n",
      " -2.44014904e-01  4.86042239e-02 -1.47963688e-01 -1.37399569e-01\n",
      "  9.28754210e-02 -3.04940939e-01 -1.18331455e-01  2.49201030e-01\n",
      " -2.93068022e-01  4.16481733e-01 -7.62431100e-02  2.89987952e-01\n",
      " -3.06022353e-02 -8.55828896e-02  7.98465163e-02  1.15255706e-01\n",
      "  1.85176492e-01 -3.06167364e-01 -3.39213461e-01  4.36664015e-01\n",
      "  8.25850368e-02  1.89638779e-01 -2.98885023e-03 -4.14474040e-01\n",
      "  2.58171380e-01 -4.75811660e-01 -5.02806306e-01  2.04509750e-01\n",
      "  2.21790954e-01 -9.93569866e-02  5.77390194e-02  5.91377430e-02\n",
      " -9.83700901e-02 -4.18492705e-02  1.24978304e-01  8.90700400e-01\n",
      " -1.79053415e-02  4.81125236e-01  1.02044746e-01 -2.26771683e-01\n",
      " -1.48750603e-01  2.07005367e-01 -1.07521653e-01 -2.91264862e-01\n",
      " -1.79052621e-01 -4.88520443e-01 -4.12543816e-03 -1.60712257e-01\n",
      " -1.10478431e-01 -1.62441537e-01  1.41812369e-01  4.34407629e-02\n",
      " -2.56233096e-01 -3.11028510e-01  1.31689727e-01  8.60177533e-05\n",
      "  8.77892971e-02  2.04542324e-01 -5.41114092e-01  2.72682071e-01\n",
      " -3.69531155e-01  2.62834638e-01  8.48337859e-02  1.18426792e-01\n",
      "  9.16295350e-02  4.35630530e-01 -7.47628836e-03 -3.62519026e-01\n",
      "  5.08690737e-02 -4.50448126e-01 -2.45256811e-01 -1.90290213e-01\n",
      " -2.10201412e-01  3.64071757e-01 -5.91524720e-01 -5.52317142e-01\n",
      "  3.60672355e-01 -1.57301202e-01 -1.33987861e-02 -1.80873752e-03\n",
      "  4.28733751e-02  3.65875736e-02 -4.50013541e-02  3.63458276e-01\n",
      " -2.24890128e-01 -1.93497121e-01  2.95833617e-01 -1.04180336e-01\n",
      " -2.27035075e-01  4.47419941e-01 -4.76988079e-03 -2.79807113e-02\n",
      " -1.10245630e-01 -6.09858073e-02  1.41674116e-01  1.21038646e-01\n",
      "  1.50842100e-01 -2.71700442e-01  4.79258835e-01  1.31807864e-01\n",
      "  3.66154492e-01  5.94604276e-02  5.41857064e-01  1.71279564e-01\n",
      " -1.77732915e-01 -1.16638087e-01 -4.56919432e-01  1.03608124e-01\n",
      "  2.38742441e-01  8.31350386e-02  5.81655949e-02 -1.76086668e-02\n",
      "  3.17636549e-01 -2.31775090e-01  3.75946552e-01  9.49818715e-02\n",
      "  1.49241343e-01  6.72189474e-01  4.22878027e-01 -9.87871587e-02\n",
      " -1.96341813e-01 -2.36011863e-01 -6.53521895e-01  7.30238343e-03\n",
      "  2.66067177e-01 -1.83145260e-03 -2.65158296e-01 -1.58292145e-01\n",
      "  6.29775133e-03  1.51390240e-01  3.85675520e-01  1.12945296e-01\n",
      "  4.93768662e-01  3.34349200e-02 -1.17495500e-01  2.38553420e-01\n",
      "  4.52716984e-02 -2.88475215e-01 -3.97076666e-01  1.23985127e-01\n",
      " -2.44537830e-01 -1.57799304e-01 -5.26146650e-01  2.95798957e-01\n",
      " -3.63416523e-01 -1.75991245e-02 -3.08920383e-01  5.17822921e-01\n",
      " -9.46139917e-02  9.12509952e-03  6.27562284e-01 -1.33058563e-01\n",
      " -4.88519408e-02 -3.17765266e-01  2.48923972e-01 -2.40618259e-01\n",
      "  1.61111027e-01 -2.79623091e-01  4.08619761e-01  5.14302075e-01\n",
      " -6.09117337e-02  3.20019335e-01 -4.73933965e-01  5.01192883e-02\n",
      "  7.68426061e-02  4.96093184e-02  2.35623810e-02  2.95782775e-01\n",
      " -1.67233236e-02 -6.66246474e-01 -6.56888008e-01  7.18736768e-01\n",
      " -4.97398198e-01 -2.14179561e-01  1.28749505e-01 -3.37260932e-01\n",
      "  4.87814061e-02 -3.94887954e-01  3.09549451e-01  3.59309763e-01\n",
      "  3.12474012e-01  9.05375779e-02  2.53023356e-01 -5.32922566e-01\n",
      " -4.57958132e-02  3.13008517e-01 -6.40174747e-02  8.67593512e-02\n",
      " -2.93599874e-01 -2.41302297e-01 -3.15045536e-01  1.42309412e-01\n",
      " -4.11642641e-01  8.25487003e-02  4.34994817e-01 -3.62617165e-01\n",
      "  2.11533591e-01 -1.10246159e-01 -2.12296456e-01 -1.69561282e-01\n",
      " -3.53897661e-01  1.66718125e-01  3.66086215e-01  5.02745330e-01\n",
      " -3.84001017e-01  1.94826767e-01 -1.38500348e-01 -2.07144335e-01\n",
      " -1.65334895e-01 -9.21110287e-02 -1.05940983e-01  8.14932659e-02\n",
      "  4.21796888e-01  2.68771891e-02  2.71846265e-01 -2.05497250e-01\n",
      "  1.50967594e-02  3.74907255e-01  4.26487923e-01  6.11077487e-01\n",
      "  3.10181767e-01  4.23645318e-01 -2.29538515e-01  1.89529926e-01]\n"
     ]
    }
   ],
   "source": [
    "ckpt = '/home/cs224u/pointer/log/pretrained_model_tf1.2.1/train/model-238410'\n",
    "v = getvalue(ckpt)\n",
    "print (len(v))\n",
    "\n",
    "print(v['seq2seq/embedding/embedding'])\n",
    "print (v['global_step'])\n",
    "print (v['seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear/Bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "[[-3.8002606e-02  1.8546827e-02  1.3938937e-01 ... -4.9497869e-02\n",
      "   3.3019509e-02  3.5647683e-02]\n",
      " [ 7.9455858e-05 -6.6116852e-05  1.3608603e-04 ... -1.5781938e-05\n",
      "   5.8481251e-05 -9.1547277e-05]\n",
      " [-5.8828846e-02  6.7614645e-02 -4.5764863e-02 ...  3.1541102e-02\n",
      "  -4.7071457e-02  1.8059494e-02]\n",
      " ...\n",
      " [ 1.8714922e-02 -3.4154747e-02 -5.7082116e-03 ...  9.0036495e-03\n",
      "  -5.3237779e-03 -3.6183164e-02]\n",
      " [ 8.1216330e-03 -1.5133495e-02 -8.5550675e-04 ... -3.6253810e-02\n",
      "  -1.3013718e-02 -1.7758729e-02]\n",
      " [ 3.4547005e-02 -3.0030517e-02 -1.4005583e-03 ... -2.2262277e-02\n",
      "   1.9773055e-02 -1.0151998e-02]]\n",
      "0\n",
      "[-5.88189960e-01  6.36716127e-01 -2.73615479e-01 -4.82237428e-01\n",
      "  5.22897661e-01 -2.45039478e-01 -1.81122139e-01 -1.61133274e-01\n",
      "  1.89639717e-01  8.96476626e-01  2.60003954e-01  5.00603676e-01\n",
      " -5.00681341e-01  1.82510480e-01  2.87051201e-01 -3.16324592e-01\n",
      "  4.16229516e-01  7.59478152e-01  1.40891239e-01  2.31299371e-01\n",
      "  1.78590983e-01 -3.56549561e-01  7.23787919e-02 -6.12765774e-02\n",
      " -2.28684410e-01  2.37101510e-01 -4.47375923e-02 -2.75556237e-01\n",
      "  4.56018001e-01  6.59986377e-01 -5.84785752e-02  3.47939640e-01\n",
      " -2.44014904e-01  4.86042239e-02 -1.47963688e-01 -1.37399569e-01\n",
      "  9.28754210e-02 -3.04940939e-01 -1.18331455e-01  2.49201030e-01\n",
      " -2.93068022e-01  4.16481733e-01 -7.62431100e-02  2.89987952e-01\n",
      " -3.06022353e-02 -8.55828896e-02  7.98465163e-02  1.15255706e-01\n",
      "  1.85176492e-01 -3.06167364e-01 -3.39213461e-01  4.36664015e-01\n",
      "  8.25850368e-02  1.89638779e-01 -2.98885023e-03 -4.14474040e-01\n",
      "  2.58171380e-01 -4.75811660e-01 -5.02806306e-01  2.04509750e-01\n",
      "  2.21790954e-01 -9.93569866e-02  5.77390194e-02  5.91377430e-02\n",
      " -9.83700901e-02 -4.18492705e-02  1.24978304e-01  8.90700400e-01\n",
      " -1.79053415e-02  4.81125236e-01  1.02044746e-01 -2.26771683e-01\n",
      " -1.48750603e-01  2.07005367e-01 -1.07521653e-01 -2.91264862e-01\n",
      " -1.79052621e-01 -4.88520443e-01 -4.12543816e-03 -1.60712257e-01\n",
      " -1.10478431e-01 -1.62441537e-01  1.41812369e-01  4.34407629e-02\n",
      " -2.56233096e-01 -3.11028510e-01  1.31689727e-01  8.60177533e-05\n",
      "  8.77892971e-02  2.04542324e-01 -5.41114092e-01  2.72682071e-01\n",
      " -3.69531155e-01  2.62834638e-01  8.48337859e-02  1.18426792e-01\n",
      "  9.16295350e-02  4.35630530e-01 -7.47628836e-03 -3.62519026e-01\n",
      "  5.08690737e-02 -4.50448126e-01 -2.45256811e-01 -1.90290213e-01\n",
      " -2.10201412e-01  3.64071757e-01 -5.91524720e-01 -5.52317142e-01\n",
      "  3.60672355e-01 -1.57301202e-01 -1.33987861e-02 -1.80873752e-03\n",
      "  4.28733751e-02  3.65875736e-02 -4.50013541e-02  3.63458276e-01\n",
      " -2.24890128e-01 -1.93497121e-01  2.95833617e-01 -1.04180336e-01\n",
      " -2.27035075e-01  4.47419941e-01 -4.76988079e-03 -2.79807113e-02\n",
      " -1.10245630e-01 -6.09858073e-02  1.41674116e-01  1.21038646e-01\n",
      "  1.50842100e-01 -2.71700442e-01  4.79258835e-01  1.31807864e-01\n",
      "  3.66154492e-01  5.94604276e-02  5.41857064e-01  1.71279564e-01\n",
      " -1.77732915e-01 -1.16638087e-01 -4.56919432e-01  1.03608124e-01\n",
      "  2.38742441e-01  8.31350386e-02  5.81655949e-02 -1.76086668e-02\n",
      "  3.17636549e-01 -2.31775090e-01  3.75946552e-01  9.49818715e-02\n",
      "  1.49241343e-01  6.72189474e-01  4.22878027e-01 -9.87871587e-02\n",
      " -1.96341813e-01 -2.36011863e-01 -6.53521895e-01  7.30238343e-03\n",
      "  2.66067177e-01 -1.83145260e-03 -2.65158296e-01 -1.58292145e-01\n",
      "  6.29775133e-03  1.51390240e-01  3.85675520e-01  1.12945296e-01\n",
      "  4.93768662e-01  3.34349200e-02 -1.17495500e-01  2.38553420e-01\n",
      "  4.52716984e-02 -2.88475215e-01 -3.97076666e-01  1.23985127e-01\n",
      " -2.44537830e-01 -1.57799304e-01 -5.26146650e-01  2.95798957e-01\n",
      " -3.63416523e-01 -1.75991245e-02 -3.08920383e-01  5.17822921e-01\n",
      " -9.46139917e-02  9.12509952e-03  6.27562284e-01 -1.33058563e-01\n",
      " -4.88519408e-02 -3.17765266e-01  2.48923972e-01 -2.40618259e-01\n",
      "  1.61111027e-01 -2.79623091e-01  4.08619761e-01  5.14302075e-01\n",
      " -6.09117337e-02  3.20019335e-01 -4.73933965e-01  5.01192883e-02\n",
      "  7.68426061e-02  4.96093184e-02  2.35623810e-02  2.95782775e-01\n",
      " -1.67233236e-02 -6.66246474e-01 -6.56888008e-01  7.18736768e-01\n",
      " -4.97398198e-01 -2.14179561e-01  1.28749505e-01 -3.37260932e-01\n",
      "  4.87814061e-02 -3.94887954e-01  3.09549451e-01  3.59309763e-01\n",
      "  3.12474012e-01  9.05375779e-02  2.53023356e-01 -5.32922566e-01\n",
      " -4.57958132e-02  3.13008517e-01 -6.40174747e-02  8.67593512e-02\n",
      " -2.93599874e-01 -2.41302297e-01 -3.15045536e-01  1.42309412e-01\n",
      " -4.11642641e-01  8.25487003e-02  4.34994817e-01 -3.62617165e-01\n",
      "  2.11533591e-01 -1.10246159e-01 -2.12296456e-01 -1.69561282e-01\n",
      " -3.53897661e-01  1.66718125e-01  3.66086215e-01  5.02745330e-01\n",
      " -3.84001017e-01  1.94826767e-01 -1.38500348e-01 -2.07144335e-01\n",
      " -1.65334895e-01 -9.21110287e-02 -1.05940983e-01  8.14932659e-02\n",
      "  4.21796888e-01  2.68771891e-02  2.71846265e-01 -2.05497250e-01\n",
      "  1.50967594e-02  3.74907255e-01  4.26487923e-01  6.11077487e-01\n",
      "  3.10181767e-01  4.23645318e-01 -2.29538515e-01  1.89529926e-01]\n",
      "dict_keys(['seq2seq/reduce_final_st/w_reduce_h/Adagrad', 'seq2seq/reduce_final_st/w_reduce_c/Adagrad', 'seq2seq/reduce_final_st/w_reduce_c', 'seq2seq/reduce_final_st/bias_reduce_c/Adagrad', 'seq2seq/output_projection/w/Adagrad', 'seq2seq/output_projection/w', 'seq2seq/reduce_final_st/w_reduce_h', 'seq2seq/output_projection/v/Adagrad', 'seq2seq/reduce_final_st/bias_reduce_c', 'seq2seq/decoder/attention_decoder/Linear/Matrix', 'seq2seq/decoder/attention_decoder/v', 'seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/kernel/Adagrad', 'seq2seq/decoder/attention_decoder/Linear/Bias/Adagrad', 'seq2seq/decoder/attention_decoder/Linear/Bias', 'seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/kernel', 'seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear_1/Bias/Adagrad', 'seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear_0/Bias', 'seq2seq/decoder/attention_decoder/W_h/Adagrad', 'seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear_0/Bias/Adagrad', 'seq2seq/reduce_final_st/bias_reduce_h', 'seq2seq/decoder/attention_decoder/Attention/Linear/Matrix', 'seq2seq/decoder/attention_decoder/calculate_pgen/Linear/Matrix', 'seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear/Matrix', 'global_step', 'seq2seq/decoder/attention_decoder/Attention/Linear/Bias/Adagrad', 'seq2seq/decoder/attention_decoder/calculate_pgen/Linear/Bias/Adagrad', 'seq2seq/decoder/attention_decoder/lstm_cell/kernel/Adagrad', 'seq2seq/output_projection/v', 'seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/bias', 'seq2seq/decoder/attention_decoder/Attention/Linear/Bias', 'seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/kernel/Adagrad', 'seq2seq/decoder/attention_decoder/Attention/Linear/Matrix/Adagrad', 'seq2seq/decoder/attention_decoder/W_h', 'seq2seq/decoder/attention_decoder/Linear/Matrix/Adagrad', 'seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear_1/Bias', 'seq2seq/decoder/attention_decoder/calculate_pgen/Linear/Bias', 'seq2seq/decoder/attention_decoder/calculate_pgen/Linear/Matrix/Adagrad', 'seq2seq/decoder/attention_decoder/lstm_cell/bias', 'seq2seq/decoder/attention_decoder/lstm_cell/bias/Adagrad', 'seq2seq/decoder/attention_decoder/lstm_cell/kernel', 'seq2seq/decoder/attention_decoder/v/Adagrad', 'seq2seq/embedding/embedding', 'seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear/Matrix/Adagrad', 'seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/bias/Adagrad', 'seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/bias/Adagrad', 'seq2seq/embedding/embedding/Adagrad', 'seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/kernel', 'seq2seq/reduce_final_st/bias_reduce_h/Adagrad', 'seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/bias'])\n"
     ]
    }
   ],
   "source": [
    "ckpt = '/home/cs224u/pointer/log/big_multi_pvocab_combine2_exp/train/model.ckpt-0'\n",
    "v_attn = getvalue(ckpt)\n",
    "print (len(value))\n",
    "\n",
    "print(v_attn['seq2seq/embedding/embedding'])\n",
    "print (v_attn['global_step'])\n",
    "print (v_attn['seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear_0/Bias'])\n",
    "print (v_attn.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "(50000, 16)\n",
      "0\n",
      "dict_keys(['seq2seq/reduce_final_st/w_reduce_c/Adagrad', 'seq2seq/reduce_final_st/w_reduce_c', 'seq2seq/reduce_final_st/bias_reduce_c/Adagrad', 'seq2seq/output_projection/w/Adagrad', 'seq2seq/output_projection/w', 'seq2seq/reduce_final_st/w_reduce_h', 'seq2seq/output_projection/v/Adagrad', 'seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/kernel/Adagrad', 'seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/kernel', 'seq2seq/reduce_final_st/w_reduce_h/Adagrad', 'seq2seq/decoder/attention_decoder/Linear_1/Bias/Adagrad', 'seq2seq/reduce_final_st/bias_reduce_c', 'seq2seq/decoder/attention_decoder/Linear/Matrix', 'seq2seq/decoder/attention_decoder/v', 'seq2seq/decoder/attention_decoder/W_h', 'seq2seq/decoder/attention_decoder/Linear/Matrix/Adagrad', 'seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/bias/Adagrad', 'seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear/Matrix/Adagrad', 'seq2seq/decoder/attention_decoder/Linear_0/Bias', 'seq2seq/decoder/attention_decoder/calculate_pgen/Linear_1/Bias', 'seq2seq/decoder/attention_decoder/lstm_cell/kernel', 'seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear/Matrix', 'seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear/Bias/Adagrad', 'seq2seq/decoder/attention_decoder/Attention/Linear/Bias', 'seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/kernel/Adagrad', 'seq2seq/reduce_final_st/bias_reduce_h', 'seq2seq/decoder/attention_decoder/Attention/Linear/Matrix', 'seq2seq/decoder/attention_decoder/Linear_0/Bias/Adagrad', 'seq2seq/decoder/attention_decoder/calculate_pgen/Linear/Matrix', 'seq2seq/decoder/attention_decoder/AttnOutputProjection/Linear/Bias', 'seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/bias/Adagrad', 'seq2seq/decoder/attention_decoder/Attention/Linear/Bias/Adagrad', 'seq2seq/decoder/attention_decoder/lstm_cell/kernel/Adagrad', 'seq2seq/output_projection/v', 'seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/bias', 'seq2seq/decoder/attention_decoder/Attention/Linear/Matrix/Adagrad', 'seq2seq/decoder/attention_decoder/W_h/Adagrad', 'seq2seq/decoder/attention_decoder/Linear_1/Bias', 'seq2seq/decoder/attention_decoder/calculate_pgen/Linear/Matrix/Adagrad', 'seq2seq/decoder/attention_decoder/calculate_pgen/Linear_0/Bias/Adagrad', 'global_step', 'seq2seq/decoder/attention_decoder/calculate_pgen/Linear_1/Bias/Adagrad', 'seq2seq/decoder/attention_decoder/lstm_cell/bias', 'seq2seq/decoder/attention_decoder/lstm_cell/bias/Adagrad', 'seq2seq/decoder/attention_decoder/v/Adagrad', 'seq2seq/decoder/attention_decoder/calculate_pgen/Linear_0/Bias', 'seq2seq/embedding/embedding', 'seq2seq/embedding/embedding/Adagrad', 'seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/kernel', 'seq2seq/reduce_final_st/bias_reduce_h/Adagrad', 'seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/bias'])\n"
     ]
    }
   ],
   "source": [
    "ckpt = '/home/cs224u/pointer/log/ckpt_multi_pgen_exp/train/model.ckpt-0'\n",
    "v_pgen = getvalue(ckpt)\n",
    "print (len(value))\n",
    "\n",
    "print(v_pgen['seq2seq/embedding/embedding'].shape)\n",
    "print (v_pgen['global_step'])\n",
    "print (v_pgen.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq2seq/decoder/attention_decoder/attn_0/v/Adagrad\n",
      "seq2seq/decoder/attention_decoder/Attention/Linear_1/Bias/Adagrad\n",
      "seq2seq/decoder/attention_decoder/Attention/Linear_0/Bias\n",
      "seq2seq/decoder/attention_decoder/Linear/Bias/Adagrad\n",
      "seq2seq/decoder/attention_decoder/Attention/Linear_0/Bias/Adagrad\n",
      "seq2seq/decoder/attention_decoder/Linear/Bias\n",
      "seq2seq/decoder/attention_decoder/attn_1/v\n",
      "seq2seq/decoder/attention_decoder/Attention/Linear_1/Bias\n",
      "seq2seq/decoder/attention_decoder/attn_1/v/Adagrad\n",
      "seq2seq/decoder/attention_decoder/calculate_pgen/Linear/Bias\n",
      "seq2seq/decoder/attention_decoder/calculate_pgen/Linear/Bias/Adagrad\n",
      "seq2seq/decoder/attention_decoder/attn_0/v\n",
      "---\n",
      "seq2seq/decoder/attention_decoder/Linear_1/Bias/Adagrad\n",
      "seq2seq/decoder/attention_decoder/v\n",
      "seq2seq/decoder/attention_decoder/Linear_0/Bias\n",
      "seq2seq/decoder/attention_decoder/calculate_pgen/Linear_1/Bias\n",
      "seq2seq/decoder/attention_decoder/Attention/Linear/Bias\n",
      "seq2seq/decoder/attention_decoder/Linear_0/Bias/Adagrad\n",
      "seq2seq/decoder/attention_decoder/Attention/Linear/Bias/Adagrad\n",
      "seq2seq/decoder/attention_decoder/Linear_1/Bias\n",
      "seq2seq/decoder/attention_decoder/calculate_pgen/Linear_0/Bias/Adagrad\n",
      "seq2seq/decoder/attention_decoder/calculate_pgen/Linear_1/Bias/Adagrad\n",
      "seq2seq/decoder/attention_decoder/v/Adagrad\n",
      "seq2seq/decoder/attention_decoder/calculate_pgen/Linear_0/Bias\n"
     ]
    }
   ],
   "source": [
    "for k in v_attn.keys():\n",
    "    if k not in v_pgen:\n",
    "        print (k)\n",
    "        \n",
    "print (\"---\")\n",
    "\n",
    "for k in v_pgen.keys():\n",
    "    if k not in v_attn:\n",
    "        print (k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'seq2seq/decoder/attention_decoder/Linear_0/Bias'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu3",
   "language": "python",
   "name": "nlu3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
